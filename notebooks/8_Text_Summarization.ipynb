{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Text Summarization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Starting logger\n"
     ]
    }
   ],
   "source": [
    "%run __init__.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "DF_FILE_PATH = os.path.join(NOTEBOOK_2_RESULTS_DIR, 'protocols_dataframe.pkl')\n",
    "\n",
    "df = pd.read_pickle(DF_FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Scratch Wound Healing Assay. Grow cells in DMEM supplemented with 10% FBS. Seed cells into 24-well tissue culture plate at a density that after 24 h of growth, they should reach ~70-80% confluence as a monolayer. Do not change the medium. Gently and slowly scratch the monolayer with a new 1 ml pipette tip across the center of the well. While scratching across the surface of the well, the long-axial of the tip should always be perpendicular to the bottom of the well. The resulting gap distance th'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "protocols_no_abstract = df['full_text_no_abstract_cleaned'].values\n",
    "protocols_no_abstract[0][:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extractive summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from string import punctuation\n",
    "\n",
    "import spacy\n",
    "import en_core_sci_lg\n",
    "\n",
    "\n",
    "nlp = en_core_sci_lg.load()\n",
    "\n",
    "def extract_summary(text, limit):\n",
    "    keyword = []\n",
    "    pos_tag = ['PROPN', 'ADJ', 'NOUN', 'VERB']\n",
    "    doc = nlp(text.lower())\n",
    "    for token in doc:\n",
    "        if(token.text in nlp.Defaults.stop_words or token.text in punctuation):\n",
    "            continue\n",
    "        if(token.pos_ in pos_tag):\n",
    "            keyword.append(token.text)\n",
    "    \n",
    "    freq_word = Counter(keyword)\n",
    "    max_freq = Counter(keyword).most_common(1)[0][1]\n",
    "    for w in freq_word:\n",
    "        freq_word[w] = (freq_word[w]/max_freq)\n",
    "        \n",
    "    sent_strength={}\n",
    "    for sent in doc.sents:\n",
    "        for word in sent:\n",
    "            if word.text in freq_word.keys():\n",
    "                if sent in sent_strength.keys():\n",
    "                    sent_strength[sent]+=freq_word[word.text]\n",
    "                else:\n",
    "                    sent_strength[sent]=freq_word[word.text]\n",
    "    \n",
    "    summary = []\n",
    "    \n",
    "    sorted_x = sorted(sent_strength.items(), key=lambda kv: kv[1], reverse=True)\n",
    "    \n",
    "    counter = 0\n",
    "    for i in range(len(sorted_x)):\n",
    "        summary.append(str(sorted_x[i][0]).capitalize())\n",
    "\n",
    "        counter += 1\n",
    "        if(counter >= limit):\n",
    "            break\n",
    "            \n",
    "    return ' '.join(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Grow cells for additional 48 h (or the time required if different cells are used). Wash the cells twice with 1x pbs, then fix the cells with 3.7% paraformaldehye for 30 min. Seed cells into 24-well tissue culture plate at a density that after 24 h of growth, they should reach ~70-80% confluence as a monolayer. After scratching, gently wash the well twice with medium to remove the detached cells.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_sentences = 4\n",
    "\n",
    "summaries = [extract_summary(t, num_sentences)\n",
    "             for t in protocols_no_abstract]\n",
    "summaries[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Scratch Wound Healing Assay. Grow cells in DMEM supplemented with 10% FBS. Seed cells into 24-well tissue culture plate at a density that after 24 h of growth, they should reach ~70-80% confluence as a monolayer. Do not change the medium. Gently and slowly scratch the monolayer with a new 1 ml pipette tip across the center of the well. While scratching across the surface of the well, the long-axial of the tip should always be perpendicular to the bottom of the well. The resulting gap distance therefore equals to the outer diameter of the end of the tip. The gap distance can be adjusted by using different types of tips. Scratch a straight line in one direction. Scratch another straight line perpendicular to the first line to create a cross in each well. After scratching, gently wash the well twice with medium to remove the detached cells. Replenish the well with fresh medium. Note: Medium may contain ingredients of interest that you want to test, e.g., chemicals that inhibit/promote cell motility and/or proliferation. Grow cells for additional 48 h (or the time required if different cells are used). Wash the cells twice with 1x PBS, then fix the cells with 3.7% paraformaldehye for 30 min. Stain the fixed cells with 1% crystal violet in 2% ethanol for 30 min. Take photos for the stained monolayer on a microscope. Set the same configurations of the microscope when taking pictures for different views of the stained monolayer. The gap distance can be quantitatively evaluated using software such as Photoshop or ImageJ (http://rsb.info.nih.gov/ij/download.html). To reduce variability in results, it’s suggested that multiple views of each well should be documented, and each experimental group should be repeated multiple times..'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "protocols_no_abstract[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstractive summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pr_id</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>materials</th>\n",
       "      <th>procedure</th>\n",
       "      <th>equipment</th>\n",
       "      <th>background</th>\n",
       "      <th>categories</th>\n",
       "      <th>authors</th>\n",
       "      <th>full_text</th>\n",
       "      <th>full_text_no_abstract</th>\n",
       "      <th>full_text_cleaned</th>\n",
       "      <th>full_text_no_abstract_cleaned</th>\n",
       "      <th>num_chars_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e100</td>\n",
       "      <td>Scratch Wound Healing Assay</td>\n",
       "      <td>The scratch wound healing assay has been widel...</td>\n",
       "      <td>Human MDA-MB-231 cell line (ATCC, catalog numb...</td>\n",
       "      <td>Grow cells in DMEM supplemented with 10% FBS.|...</td>\n",
       "      <td>BD Falcon 24-well tissue culture plate (Fisher...</td>\n",
       "      <td></td>\n",
       "      <td>Cancer Biology|Invasion &amp; metastasis|Cell biol...</td>\n",
       "      <td>Yanling Chen</td>\n",
       "      <td>Scratch Wound Healing Assay. The scratch wound...</td>\n",
       "      <td>Scratch Wound Healing Assay. Grow cells in DME...</td>\n",
       "      <td>Scratch Wound Healing Assay. The scratch wound...</td>\n",
       "      <td>Scratch Wound Healing Assay. Grow cells in DME...</td>\n",
       "      <td>2583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e1029</td>\n",
       "      <td>ADCC Assay Protocol</td>\n",
       "      <td>Antibody-dependent cell-mediated cytotoxicity ...</td>\n",
       "      <td>Raji cells (ATCC)|A/California/04/2009 (H1N1) ...</td>\n",
       "      <td>Preperation of Target Cells\\n\\n\\t\\t\\n\\n\\n\\t\\t\\...</td>\n",
       "      <td>Round bottomed 96-well plate|Temperature contr...</td>\n",
       "      <td></td>\n",
       "      <td>Immunology|Immune cell function|Cytotoxicity|C...</td>\n",
       "      <td>Vikram  Srivastava|Zheng  Yang|Ivan  Fan  Ngai...</td>\n",
       "      <td>ADCC Assay Protocol. Antibody-dependent cell-m...</td>\n",
       "      <td>ADCC Assay Protocol. Preperation of Target Cel...</td>\n",
       "      <td>ADCC Assay Protocol. Antibody-dependent cell-m...</td>\n",
       "      <td>ADCC Assay Protocol. Preperation of Target Cel...</td>\n",
       "      <td>3824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e1072</td>\n",
       "      <td>Catalase Activity Assay in Candida glabrata</td>\n",
       "      <td>Commensal and pathogenic fungi are exposed to ...</td>\n",
       "      <td>Yeast strains \\nNote: BG14 was used as the C. ...</td>\n",
       "      <td>Preparation of total soluble extracts\\n\\t\\t\\n\\...</td>\n",
       "      <td>Orbital incubator shaker|Microfuge tubes|50 ml...</td>\n",
       "      <td></td>\n",
       "      <td>Microbiology|Microbial biochemistry|Protein|Ac...</td>\n",
       "      <td>Emmanuel  Orta-Zavalza|Marcela  Briones-Martin...</td>\n",
       "      <td>Catalase Activity Assay in Candida glabrata. C...</td>\n",
       "      <td>Catalase Activity Assay in Candida glabrata. P...</td>\n",
       "      <td>Catalase Activity Assay in Candida glabrata. C...</td>\n",
       "      <td>Catalase Activity Assay in Candida glabrata. P...</td>\n",
       "      <td>4207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e1077</td>\n",
       "      <td>RNA Isolation and Northern Blot Analysis</td>\n",
       "      <td>The northern blot is a technique used in molec...</td>\n",
       "      <td>Vero cells (kidney epithelial cells extracted ...</td>\n",
       "      <td>RNA extraction\\n\\t\\t\\n\\n\\t\\t\\t\\tCells were see...</td>\n",
       "      <td>100 mm cell culture dishes (Corning, catalog n...</td>\n",
       "      <td></td>\n",
       "      <td>Microbiology|Microbial genetics|RNA|RNA extrac...</td>\n",
       "      <td>Ying Liao|To Sing Fung|Mei Huang|Shouguo Fang|...</td>\n",
       "      <td>RNA Isolation and Northern Blot Analysis. The ...</td>\n",
       "      <td>RNA Isolation and Northern Blot Analysis. RNA ...</td>\n",
       "      <td>RNA Isolation and Northern Blot Analysis. The ...</td>\n",
       "      <td>RNA Isolation and Northern Blot Analysis. RNA ...</td>\n",
       "      <td>6890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e1090</td>\n",
       "      <td>Flow Cytometric Analysis of Autophagic Activit...</td>\n",
       "      <td>Flow cytometry allows very sensitive and relia...</td>\n",
       "      <td>Cells lines of interest (HepG2, HUH7, CMK, K56...</td>\n",
       "      <td>Maintain cells under standard tissue culture c...</td>\n",
       "      <td>37 °C, 5% CO2 humidified incubator|Centrifuge|...</td>\n",
       "      <td></td>\n",
       "      <td>Microbiology|Antimicrobial assay|Autophagy ass...</td>\n",
       "      <td>Metodi  Stankov|Diana  Panayotova-Dimitrova|Ma...</td>\n",
       "      <td>Flow Cytometric Analysis of Autophagic Activit...</td>\n",
       "      <td>Flow Cytometric Analysis of Autophagic Activit...</td>\n",
       "      <td>Flow Cytometric Analysis of Autophagic Activit...</td>\n",
       "      <td>Flow Cytometric Analysis of Autophagic Activit...</td>\n",
       "      <td>5890</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pr_id                                              title  \\\n",
       "0   e100                        Scratch Wound Healing Assay   \n",
       "1  e1029                                ADCC Assay Protocol   \n",
       "2  e1072        Catalase Activity Assay in Candida glabrata   \n",
       "3  e1077           RNA Isolation and Northern Blot Analysis   \n",
       "4  e1090  Flow Cytometric Analysis of Autophagic Activit...   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  The scratch wound healing assay has been widel...   \n",
       "1  Antibody-dependent cell-mediated cytotoxicity ...   \n",
       "2  Commensal and pathogenic fungi are exposed to ...   \n",
       "3  The northern blot is a technique used in molec...   \n",
       "4  Flow cytometry allows very sensitive and relia...   \n",
       "\n",
       "                                           materials  \\\n",
       "0  Human MDA-MB-231 cell line (ATCC, catalog numb...   \n",
       "1  Raji cells (ATCC)|A/California/04/2009 (H1N1) ...   \n",
       "2  Yeast strains \\nNote: BG14 was used as the C. ...   \n",
       "3  Vero cells (kidney epithelial cells extracted ...   \n",
       "4  Cells lines of interest (HepG2, HUH7, CMK, K56...   \n",
       "\n",
       "                                           procedure  \\\n",
       "0  Grow cells in DMEM supplemented with 10% FBS.|...   \n",
       "1  Preperation of Target Cells\\n\\n\\t\\t\\n\\n\\n\\t\\t\\...   \n",
       "2  Preparation of total soluble extracts\\n\\t\\t\\n\\...   \n",
       "3  RNA extraction\\n\\t\\t\\n\\n\\t\\t\\t\\tCells were see...   \n",
       "4  Maintain cells under standard tissue culture c...   \n",
       "\n",
       "                                           equipment background  \\\n",
       "0  BD Falcon 24-well tissue culture plate (Fisher...              \n",
       "1  Round bottomed 96-well plate|Temperature contr...              \n",
       "2  Orbital incubator shaker|Microfuge tubes|50 ml...              \n",
       "3  100 mm cell culture dishes (Corning, catalog n...              \n",
       "4  37 °C, 5% CO2 humidified incubator|Centrifuge|...              \n",
       "\n",
       "                                          categories  \\\n",
       "0  Cancer Biology|Invasion & metastasis|Cell biol...   \n",
       "1  Immunology|Immune cell function|Cytotoxicity|C...   \n",
       "2  Microbiology|Microbial biochemistry|Protein|Ac...   \n",
       "3  Microbiology|Microbial genetics|RNA|RNA extrac...   \n",
       "4  Microbiology|Antimicrobial assay|Autophagy ass...   \n",
       "\n",
       "                                             authors  \\\n",
       "0                                       Yanling Chen   \n",
       "1  Vikram  Srivastava|Zheng  Yang|Ivan  Fan  Ngai...   \n",
       "2  Emmanuel  Orta-Zavalza|Marcela  Briones-Martin...   \n",
       "3  Ying Liao|To Sing Fung|Mei Huang|Shouguo Fang|...   \n",
       "4  Metodi  Stankov|Diana  Panayotova-Dimitrova|Ma...   \n",
       "\n",
       "                                           full_text  \\\n",
       "0  Scratch Wound Healing Assay. The scratch wound...   \n",
       "1  ADCC Assay Protocol. Antibody-dependent cell-m...   \n",
       "2  Catalase Activity Assay in Candida glabrata. C...   \n",
       "3  RNA Isolation and Northern Blot Analysis. The ...   \n",
       "4  Flow Cytometric Analysis of Autophagic Activit...   \n",
       "\n",
       "                               full_text_no_abstract  \\\n",
       "0  Scratch Wound Healing Assay. Grow cells in DME...   \n",
       "1  ADCC Assay Protocol. Preperation of Target Cel...   \n",
       "2  Catalase Activity Assay in Candida glabrata. P...   \n",
       "3  RNA Isolation and Northern Blot Analysis. RNA ...   \n",
       "4  Flow Cytometric Analysis of Autophagic Activit...   \n",
       "\n",
       "                                   full_text_cleaned  \\\n",
       "0  Scratch Wound Healing Assay. The scratch wound...   \n",
       "1  ADCC Assay Protocol. Antibody-dependent cell-m...   \n",
       "2  Catalase Activity Assay in Candida glabrata. C...   \n",
       "3  RNA Isolation and Northern Blot Analysis. The ...   \n",
       "4  Flow Cytometric Analysis of Autophagic Activit...   \n",
       "\n",
       "                       full_text_no_abstract_cleaned  num_chars_text  \n",
       "0  Scratch Wound Healing Assay. Grow cells in DME...            2583  \n",
       "1  ADCC Assay Protocol. Preperation of Target Cel...            3824  \n",
       "2  Catalase Activity Assay in Candida glabrata. P...            4207  \n",
       "3  RNA Isolation and Northern Blot Analysis. RNA ...            6890  \n",
       "4  Flow Cytometric Analysis of Autophagic Activit...            5890  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df['full_text_no_abstract_cleaned'].values\n",
    "y_true = df['abstract'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-large-cnn/config.json from cache at C:\\Users\\alex/.cache\\torch\\transformers\\5f0de1d2bbb8eb1a3b69656622293b3328b06b701663a9d4109359751cb4e739.5e72c6158467741b29afbcad014cd97414f17a191d39253eef90d7bfe969cc1f\n",
      "INFO:transformers.configuration_utils:Model config BartConfig {\n",
      "  \"_num_labels\": 3,\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 4096,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 12,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 16,\n",
      "  \"encoder_ffn_dim\": 4096,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 12,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"extra_pos_embeddings\": 2,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 142,\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"min_length\": 56,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"prefix\": \" \",\n",
      "  \"scale_embedding\": false,\n",
      "  \"static_position_embeddings\": false,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 142,\n",
      "      \"min_length\": 56,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4\n",
      "    }\n",
      "  },\n",
      "  \"vocab_size\": 50264\n",
      "}\n",
      "\n",
      "INFO:transformers.modeling_utils:loading weights file https://cdn.huggingface.co/facebook/bart-large-cnn/pytorch_model.bin from cache at C:\\Users\\alex/.cache\\torch\\transformers\\579dd21941940697e1fe35c8963e41bebe3260ff761dc99fe01f2d8f9a699996.73d71f0899e4bd27603a3503868c9f8cf938416df2de374c864a8c3af18f981d\n",
      "INFO:transformers.modeling_utils:All model checkpoint weights were used when initializing BartForConditionalGeneration.\n",
      "\n",
      "INFO:transformers.modeling_utils:All the weights of BartForConditionalGeneration were initialized from the model checkpoint at facebook/bart-large-cnn.\n",
      "If your task is similar to the task the model of the ckeckpoint was trained on, you can already use BartForConditionalGeneration for predictions without further training.\n",
      "INFO:transformers.tokenization_utils_base:loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json from cache at C:\\Users\\alex/.cache\\torch\\transformers\\1ae1f5b6e2b22b25ccc04c000bb79ca847aa226d0761536b011cf7e5868f0655.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n",
      "INFO:transformers.tokenization_utils_base:loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt from cache at C:\\Users\\alex/.cache\\torch\\transformers\\f8f83199a6270d582d6245dc100e99c4155de81c9745c6248077018fe01abcfb.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Scratch Wound Healing Assay. Grow cells in DMEM supplemented with 10% FBS. Seed cells into 24-well tissue culture plate at a density that after 24 h of growth, they should reach ~70-80% confluence as a monolayer. Do not change the medium.']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BartTokenizer, BartForConditionalGeneration, BartConfig\n",
    "\n",
    "model = BartForConditionalGeneration.from_pretrained('facebook/bart-large-cnn')\n",
    "tokenizer = BartTokenizer.from_pretrained('facebook/bart-large-cnn')\n",
    "\n",
    "inputs = tokenizer(x[0], return_tensors='pt')\n",
    "summary_ids = model.generate(inputs['input_ids'])\n",
    "result = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=False)\n",
    "         for g in summary_ids]\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM\n",
    "\n",
    "model_dirs = ['bart_cnn', 'bart_xsum',\n",
    "              'distillbart_cnn_protocols',\n",
    "              'distillbart_xsum_protocols']\n",
    "base_model_dir = os.path.join(DATA_DIR, 'text_summarization_models')\n",
    "\n",
    "for model_dir in model_dirs:\n",
    "    complete_model_path = os.path.join(os.path.join(base_model_dir, model_dir), 'best_tfmr')\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(complete_model_path)\n",
    "    model..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:transformers.configuration_utils:loading configuration file E:\\hercules\\hercules-challenge-protocols\\data\\text_summarization_models\\distillbart_xsum_protocols\\best_tfmr\\config.json\n",
      "INFO:transformers.configuration_utils:Model config BartConfig {\n",
      "  \"_num_labels\": 3,\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 4096,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 16,\n",
      "  \"encoder_ffn_dim\": 4096,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 12,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"eos_token_ids\": [\n",
      "    2\n",
      "  ],\n",
      "  \"extra_pos_embeddings\": 2,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"length_penalty\": 0.5,\n",
      "  \"max_length\": 62,\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"min_length\": 11,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_beams\": 6,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"prefix\": \" \",\n",
      "  \"replacing_rate\": 0,\n",
      "  \"save_step\": 11,\n",
      "  \"scale_embedding\": false,\n",
      "  \"static_position_embeddings\": false,\n",
      "  \"student_decoder_layers\": null,\n",
      "  \"student_encoder_layers\": null,\n",
      "  \"task_specific_params\": {},\n",
      "  \"vocab_size\": 50264\n",
      "}\n",
      "\n",
      "INFO:transformers.modeling_utils:loading weights file E:\\hercules\\hercules-challenge-protocols\\data\\text_summarization_models\\distillbart_xsum_protocols\\best_tfmr\\pytorch_model.bin\n",
      "INFO:transformers.modeling_utils:All model checkpoint weights were used when initializing BartForConditionalGeneration.\n",
      "\n",
      "INFO:transformers.modeling_utils:All the weights of BartForConditionalGeneration were initialized from the model checkpoint at E:\\hercules\\hercules-challenge-protocols\\data\\text_summarization_models\\distillbart_xsum_protocols\\best_tfmr.\n",
      "If your task is similar to the task the model of the ckeckpoint was trained on, you can already use BartForConditionalGeneration for predictions without further training.\n",
      "INFO:transformers.configuration_utils:loading configuration file E:\\hercules\\hercules-challenge-protocols\\data\\text_summarization_models\\distillbart_xsum_protocols\\best_tfmr\\config.json\n",
      "INFO:transformers.configuration_utils:Model config BartConfig {\n",
      "  \"_num_labels\": 3,\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 4096,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 16,\n",
      "  \"encoder_ffn_dim\": 4096,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 12,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"eos_token_ids\": [\n",
      "    2\n",
      "  ],\n",
      "  \"extra_pos_embeddings\": 2,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"length_penalty\": 0.5,\n",
      "  \"max_length\": 62,\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"min_length\": 11,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_beams\": 6,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"prefix\": \" \",\n",
      "  \"replacing_rate\": 0,\n",
      "  \"save_step\": 11,\n",
      "  \"scale_embedding\": false,\n",
      "  \"static_position_embeddings\": false,\n",
      "  \"student_decoder_layers\": null,\n",
      "  \"student_encoder_layers\": null,\n",
      "  \"task_specific_params\": {},\n",
      "  \"vocab_size\": 50264\n",
      "}\n",
      "\n",
      "INFO:transformers.tokenization_utils_base:Model name 'E:\\hercules\\hercules-challenge-protocols\\data\\text_summarization_models\\distillbart_xsum_protocols\\best_tfmr' not found in model shortcut name list (facebook/bart-base, facebook/bart-large, facebook/bart-large-mnli, facebook/bart-large-cnn, facebook/bart-large-xsum, yjernite/bart_eli5). Assuming 'E:\\hercules\\hercules-challenge-protocols\\data\\text_summarization_models\\distillbart_xsum_protocols\\best_tfmr' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
      "INFO:transformers.tokenization_utils_base:Didn't find file E:\\hercules\\hercules-challenge-protocols\\data\\text_summarization_models\\distillbart_xsum_protocols\\best_tfmr\\added_tokens.json. We won't load it.\n",
      "INFO:transformers.tokenization_utils_base:Didn't find file E:\\hercules\\hercules-challenge-protocols\\data\\text_summarization_models\\distillbart_xsum_protocols\\best_tfmr\\tokenizer.json. We won't load it.\n",
      "INFO:transformers.tokenization_utils_base:loading file E:\\hercules\\hercules-challenge-protocols\\data\\text_summarization_models\\distillbart_xsum_protocols\\best_tfmr\\vocab.json\n",
      "INFO:transformers.tokenization_utils_base:loading file E:\\hercules\\hercules-challenge-protocols\\data\\text_summarization_models\\distillbart_xsum_protocols\\best_tfmr\\merges.txt\n",
      "INFO:transformers.tokenization_utils_base:loading file None\n",
      "INFO:transformers.tokenization_utils_base:loading file E:\\hercules\\hercules-challenge-protocols\\data\\text_summarization_models\\distillbart_xsum_protocols\\best_tfmr\\special_tokens_map.json\n",
      "INFO:transformers.tokenization_utils_base:loading file E:\\hercules\\hercules-challenge-protocols\\data\\text_summarization_models\\distillbart_xsum_protocols\\best_tfmr\\tokenizer_config.json\n",
      "INFO:transformers.tokenization_utils_base:loading file None\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "DEFAULT_DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "def chunks(lst, n):\n",
    "    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n",
    "    for i in range(0, len(lst), n):\n",
    "        yield lst[i : i + n]\n",
    "\n",
    "def trim_batch(input_ids, pad_token_id, attention_mask=None):\n",
    "    \"\"\"Remove columns that are populated exclusively by pad_token_id\"\"\"\n",
    "    keep_column_mask = input_ids.ne(pad_token_id).any(dim=0)\n",
    "    if attention_mask is None:\n",
    "        return input_ids[:, keep_column_mask]\n",
    "    else:\n",
    "        return (input_ids[:, keep_column_mask], attention_mask[:, keep_column_mask])\n",
    "\n",
    "\n",
    "complete_model_path = os.path.join(os.path.join(base_model_dir, 'distillbart_xsum_protocols'), 'best_tfmr')\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(complete_model_path).to(DEFAULT_DEVICE)\n",
    "tokenizer = AutoTokenizer.from_pretrained(complete_model_path)\n",
    "\n",
    "results = []\n",
    "for doc in x:\n",
    "    batch = tokenizer(doc, return_tensors=\"pt\", truncation=True, padding=\"max_length\").to(DEFAULT_DEVICE)\n",
    "    input_ids, attention_mask = trim_batch(**batch, pad_token_id=tokenizer.pad_token_id)\n",
    "    summaries = model.generate(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        decoder_start_token_id=None\n",
    "    )\n",
    "    dec = tokenizer.batch_decode(summaries, skip_special_tokens=True, clean_up_tokenization_spaces=False)\n",
    "    results.append(dec[0])\n",
    "    if len(dec) != 1:\n",
    "        print('AAAAA?')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Scratch Wound Healing Assay is a scratch-wound healing assay that can be used to determine whether a wound can be healed or not.'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The scratch wound healing assay has been widely adapted and modified to study the effects of a variety of experimental conditions, for instance, gene knockdown or chemical exposure, on mammalian cell migration and proliferation. In a typical scratch wound healing assay, a “wound gap” in a cell monolayer is created by scratching, and the “healing” of this gap by cell migration and growth towards the center of the gap is monitored and often quantitated.  Factors that alter the motility and/or growth of the cells can lead to increased or decreased rate of “healing” of the gap (Lampugnani, 1999). This assay is simple, inexpensive, and experimental conditions can be easily adjusted for different purposes. The assay can also be used for a high-throughput screen platform if an automated system is used (Yarrow and Perlman, 2004).'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from rouge_score import rouge_scorer\n",
    "\n",
    "def compute_rouge_fscores(results, y):\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rougeL'], use_stemmer=True)\n",
    "    rouge1_scores = []\n",
    "    rougel_scores = []\n",
    "\n",
    "    for y_pred, y_true in zip(results, y):\n",
    "        rouge_score = scorer.score(y_pred, y_true)\n",
    "        rouge1_scores.append(rouge_score['rouge1'].fmeasure)\n",
    "        rougel_scores.append(rouge_score['rougeL'].fmeasure)\n",
    "\n",
    "    return (np.mean(rouge1_scores), np.mean(rougel_scores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16371107501329363"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_score_rougel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
